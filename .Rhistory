TRUEMAX <- 20
N_IND_SAMPLES <- 1000
SAMPLESIZE <- 10
lots <- 100000
datafountain <- runif(lots,TRUEMIN,TRUEMAX)
samplemean <- numeric(N_IND_SAMPLES)
for(i in 1:N_IND_SAMPLES){
sample <- sample(datafountain,SAMPLESIZE)
samplemean[i] <- mean(sample)
}
hist(datafountain,freq=F,ylim=c(0,1))
hist(samplemean,freq=F,add=T,col="red")
air.cleaned <- na.omit(airquality) # you can call whatâ€™s created on the left-hand side anything you want!
stats:::plot.lm(model1, which=c(1:4))   # in some cases, need to make sure the package is explicitly referenced!
?plot.lm
?rstandard
?rstudent
?plot.lm
?symbols
air.cleaned
symbols(Temp, Solar.R, Ozone/100, ylab="Solar Radiation", xlab="Temperature", main="Interaction Plot", inches=FALSE,data=air.cleaned)
with(air.cleaned,
symbols(Temp, Solar.R, Ozone/100, ylab="Solar Radiation", xlab="Temperature", main="Interaction Plot", inches=FALSE)
)
with(air.cleaned,
symbols(Temp, Solar.R, circles=Ozone/100, ylab="Solar Radiation", xlab="Temperature", main="Interaction Plot", inches=FALSE)
)
?coplot
attach(air.cleaned)
coplot(Ozone~Solar|Temp)
coplot(Ozone~Solar.R|Temp)
coplot(Ozone~Temp|Solar.R)
?coplot
ll.dm <- lat ~ long | depth * mag
coplot(ll.dm, data = quakes)
coplot(lat ~ long | depth, data = quakes)
coplot(Ozone~Temp|Solar.R)
coplot(Ozone~Temp|Solar.R,rows=1)
with(air.cleaned, # with"" is a way to temporarily "attach" a data set to the workspace
{symbols(Temp, Solar.R, circles=Ozone/100, ylab="Solar Radiation", xlab="Temperature", main="Interaction Plot", inches=FALSE);
coplot(Ozone~Temp|Solar.R,rows=1)}
)
with(air.cleaned, # with"" is a way to temporarily "attach" a data set to the workspace
{symbols(Temp, Solar.R, circles=Ozone/100, ylab="Solar Radiation", xlab="Temperature", main="Interaction Plot", inches=FALSE);
coplot(Ozone~Temp|Solar.R,rows=1)}
)
with(air.cleaned, # with"" is a way to temporarily "attach" a data set to the workspace
symbols(Temp, Solar.R, circles=Ozone/100, ylab="Solar Radiation", xlab="Temperature", main="Interaction Plot", inches=FALSE)
)
with(air.cleaned, # with"" is a way to temporarily "attach" a data set to the workspace
symbols(Temp, Solar.R, circles=Ozone/100, ylab="Solar Radiation", xlab="Temperature", main="Interaction Plot", inches=FALSE)
)
formula <- Ozone ~ Wind + Solar.R * Temp    # you can name formulas...
formula2 <- Ozone ~ Wind + Solar.R * Temp    # you can name formulas...
formula2 <- Ozone ~ Wind + Solar.R * Temp    # you can name formulas...
model2 <- lm(formula,data=air.cleaned)
model2 <- lm(formula,data=air.cleaned)
anova(model1, model2.lm, test="F")
anova(model1, model2, test="F")
anova(model1, model2, test="LRT")
AIC(model1)
AIC(model2)
anova(model1, model2, test="F")
NobleFir.df <- read.csv("TreeData.csv")
cor(NobleFir.df[,c(2,4,7:9)])
boxplot(NobleFir.df$ABPR~NobleFir.df$SlopePos)
boxplot(NobleFir.df$ABPR~NobleFir.df$Northeastness)   # for example
boxplot(NobleFir.df$ABPR,NobleFir.df$Northeastness)   # for example
plot(NobleFir.df$ABPR~NobleFir.df$Northeastness)   # for example
boxplot(NobleFir.df$ABPR,NobleFir.df$Northeastness)   # for example
NobleFir.df$ABPR
?boxplot
boxplot(NobleFir.df$Northeastness~NobleFir.df$ABPR)   # for example
boxplot(NobleFir.df$Northeastness~NobleFir.df$ABPR, xlab="Presence of Noble Fir", ylab="Northeastness")   # for example
Biomass_std.lm <- lm(scale(Biomass) ~ scale(elev) + scale(Northeastness) + scale(Slope) + SlopePos + scale(StandAge))
with(NobleFir.df,
Biomass_std.lm <- lm(scale(Biomass) ~ scale(elev) + scale(Northeastness) + scale(Slope) + SlopePos + scale(StandAge))
)
with(NobleFir.df,
Biomass_std.lm <- lm(scale(Biomass) ~ scale(elev) + scale(Northeastness) + scale(Slope) + SlopePos + scale(StandAge))
)
Biomass_std.lm
Biomass_std.lm <- with(NobleFir.df,
lm(scale(Biomass) ~ scale(elev) + scale(Northeastness) + scale(Slope) + SlopePos + scale(StandAge))
)
Biomass_std.lm
symbols(x,y,circles=abs(residuals(Biomass_std.lm)), inches=0.3, ylab="Northing", xlab="Easting", main="Errors from Biomass Regression Model")
with(NobleFir.df,
symbols(x,y,circles=abs(residuals(Biomass_std.lm)), inches=0.3, ylab="Northing", xlab="Easting", main="Errors from Biomass Regression Model")
)
boxplot(NobleFir.df$Northeastness~NobleFir.df$ABPR, xlab="Presence of Noble Fir", ylab="Northeastness")   # for example
cor(NobleFir.df[,c(2,4,7:9)])
NobleFir.df <- read.csv("TreeData.csv")
model2 <- lm(formula,data=air.cleaned)
formula2 <- Ozone ~ Wind + Solar.R * Temp    # you can name formulas...
with(air.cleaned, # with"" is a way to temporarily "attach" a data set to the workspace
symbols(Temp, Solar.R, circles=Ozone/100, ylab="Solar Radiation", xlab="Temperature", main="Interaction Plot", inches=FALSE)
)
# alternatively...
with(air.cleaned,
coplot(Ozone~Temp|Solar.R,rows=1)
)
Biomass_std.lm <- with(NobleFir.df,
lm(scale(Biomass) ~ scale(elev) + scale(Northeastness) + scale(Slope) + SlopePos + scale(StandAge))
)
Biomass_std.lm <- with(NobleFir.df,
lm(scale(Biomass) ~ scale(elev) + scale(Northeastness) + scale(Slope) + SlopePos + scale(StandAge))
)
Biomass_std.lm <- with(NobleFir.df,
lm(scale(Biomass) ~ scale(elev) + scale(Northeastness) + scale(Slope) + SlopePos + scale(StandAge))
)
Biomass_std.lm
boxplot(NobleFir.df$Northeastness~NobleFir.df$ABPR, xlab="Presence of Noble Fir", ylab="Northeastness")   # for example
cor(NobleFir.df[,c(2,4,7:9)])
NobleFir.df <- read.csv("TreeData.csv")
formula2 <- Ozone ~ Wind + Solar.R * Temp    # you can name formulas...
model2 <- lm(formula,data=air.cleaned)
detach()
detach()
detach()
detach()
detach()
detach()
detach()
detach()
detach()
detach()
formula2 <- as.formula("Ozone ~ Wind + Solar.R * Temp")    # you can name formulas...
formula2 <- "Ozone ~ Wind + Solar.R * Temp"
library(rmarkdown)
library("evaluate", lib.loc="~/R/win-library/3.3")
library("yaml", lib.loc="~/R/win-library/3.3")
library("htmltools", lib.loc="~/R/win-library/3.3")
library("knitr", lib.loc="~/R/win-library/3.3")
library("lazyeval", lib.loc="~/R/win-library/3.3")
library("dplyr", lib.loc="~/R/win-library/3.3")
library("Rcpp", lib.loc="~/R/win-library/3.3")
library("markdown", lib.loc="~/R/win-library/3.3")
detach("package:markdown", unload=TRUE)
library("markdown", lib.loc="~/R/win-library/3.3")
library("magrittr", lib.loc="~/R/win-library/3.3")
library("stats", lib.loc="C:/Program Files/R/R-3.3.1/library")
data <- data.frame(
GroupA = c(175, 168, 168, 190, 156, 181, 182, 175, 174, 179),
GroupB = c(185, 169, 173, 173, 188, 186, 175, 174, 179, 180)
)
summary(data)
sample.size <- length(data$GroupA)
reshape_data <- data.frame(
Group = rep(c("A","B"),each=sample.size),
Mass = c(data$GroupA,data$GroupB)
)
plot(Height~Group, data=reshape_data)
boxplot(GroupA,GroupB,data=data,names=c("GroupA","GroupB"))
data
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
summary(data)
sample.size <- length(data$GroupA)
reshape_data <- data.frame(
Group = rep(c("A","B"),each=sample.size),
Mass = c(data$GroupA,data$GroupB)
)
plot(Height~Group, data=reshape_data)
plot(Mass~Group, data=reshape_data)
boxplot(GroupA,GroupB,data=data,names=c("GroupA","GroupB"))
data$GroupA
boxplot(data$GroupA,data$GroupB,names=c("GroupA","GroupB"))
df <- data.frame(
GroupA = c(175, 168, 168, 190, 156, 181, 182, 175, 174, 179),
GroupB = c(185, 169, 173, 173, 188, 186, 175, 174, 179, 180)
)
summary(df)
sample.size <- length(df$GroupA)
df <- data.frame(
GroupA = c(175, 168, 168, 190, 156, 181, 182, 175, 174, 179),
GroupB = c(185, 169, 173, 173, 188, 186, 175, 174, 179, 180)
)
summary(df)
sample.size <- length(df$GroupA)
reshape_df <- data.frame(
Group = rep(c("A","B"),each=sample.size),
Mass = c(df$GroupA,df$GroupB)
)
plot(Mass~Group, data=reshape_df)
observed_dif <- mean(df$GroupA) - mean(df$GroupB)
observed_dif
df <- data.frame(
GroupA = c(175, 168, 168, 190, 156, 181, 182, 175, 174, 179),
GroupB = c(185, 169, 173, 173, 188, 186, 175, 174, 179, 180)
)
boxplot(df$GroupA,df$GroupB,names=c("GroupA","GroupB"))
observed_dif <- mean(df$GroupA) - mean(df$GroupB)
observed_dif
t.test(df$GroupA,df$GroupB, var.equal=TRUE, paired=FALSE)
df <- data.frame(
GroupA = c(175, 168, 168, 190, 156, 181, 182, 175, 174, 179),
GroupB = c(185, 169, 173, 173, 188, 186, 175, 174, 179, 180)
)
summary(df)
sample.size <- length(df$GroupA)
reshape_df <- data.frame(
Group = rep(c("A","B"),each=sample.size),
Mass = c(df$GroupA,df$GroupB)
)
plot(Mass~Group, data=reshape_df)
boxplot(df$GroupA,df$GroupB,names=c("GroupA","GroupB"))  # (alternative method!)
plot(Mass~Group, data=reshape_df)
observed_dif <- mean(df$GroupA) - mean(df$GroupB)
observed_dif
t.test(df$GroupA,df$GroupB, var.equal=TRUE, paired=FALSE)
popMean_null <- mean(reshape_df$Height)        # assume groups A and B come from a population with common mean
popMean_null <- mean(reshape_df$Mass)        # assume groups A and B come from a population with common mean
popMean_null <- mean(reshape_df$Mass)        # assume groups A and B come from a population with common mean
popSD_null <- sd(reshape_data$Mass)
popMean_null <- mean(reshape_df$Mass)        # assume groups A and B come from a population with common mean
popSD_null <- sd(reshape_data$Mass)
popData_null <- rnorm(n=lots,mean=popMean_null,sd=popSD_null)    # the statistical "population" of interest (under null model)
lots <- 1000000  # large number approximating infinity in this example!
popData_null <- rnorm(n=lots,mean=popMean_null,sd=popSD_null)    # the statistical "population" of interest (under null model)
sampleA <- sample(popData_null,size=sample.size)
sampleB <- sample(popData_null,size=sample.size)
sampleA
sampleB
round(sampleA)
difference <- mean(sampleA)-mean(sampleB)   # difference between sample means
difference
reps <- 1000
null_difs <- numeric(reps)
reps <- 1000
null_difs <- numeric(reps)
for(i in 1:reps){
sampleA <- sample(popData_null,size=sample.size)
sampleB <- sample(popData_null,size=sample.size)
null_difs[i] <- mean(sampleA)-mean(sampleB)
}
hist(null_difs)
abline(v=observed_dif,col="green",lwd=3)
hist(null_difs)
abline(v=observed_dif,col="green",lwd=3)
ordered_difs <- sort(abs(null_difs))   # first order the distribution of null results in terms of absolute magnitude of difference
higher_anomaly <- length(which(ordered_difs>=abs(observed_dif)))
p_value <- higher_anomaly/reps   # probability of getting a value with anomaly as or more extreme than observed, given null hypothesis is true...
p_value
many <- 5000
null_difs <- numeric(many)
i=1
newindices <- sample(c(1:nrow(reshape_df)))
newGroup <- reshape_df$Group[newindices]
newGroup
newGroup=="A"
newGroup=="B"
MGD <- reshape_df$Mass[newGroup=="A"]	- reshape_df$Mass[newGroup=="B"]
many <- 5000
null_difs <- numeric(many)
for (i in 1:many){
newindices <- sample(c(1:nrow(reshape_df)))
newGroup <- reshape_df$Group[newindices]
dif <- reshape_df$Mass[newGroup=="A"]	- reshape_df$Mass[newGroup=="B"]
null_difs[i] <- dif
}
many <- 5000
null_difs <- numeric(many)
for (i in 1:many){
newindices <- sample(c(1:nrow(reshape_df)))
newGroup <- reshape_df$Group[newindices]
dif <- reshape_df$Mass[newGroup=="A"]	- reshape_df$Mass[newGroup=="B"]
null_difs[i] <- dif
}
c(1:nrow(reshape_df))
newindices <- sample(c(1:nrow(reshape_df)))
newGroup <- reshape_df$Group[newindices]
reshape_df$Mass[newGroup=="A"]
dif <- mean(reshape_df$Mass[newGroup=="A"])	- mean(reshape_df$Mass[newGroup=="B"])
dif
null_difs[i] <- dif
many <- 5000
null_difs <- numeric(many)
for (i in 1:many){
newindices <- sample(c(1:nrow(reshape_df)))
newGroup <- reshape_df$Group[newindices]
dif <- mean(reshape_df$Mass[newGroup=="A"])	- mean(reshape_df$Mass[newGroup=="B"])
null_difs[i] <- dif
}
hist(null_difs)
hist(null_difs)
abline(v=observed_dif,col="green",lwd=3)
sort(abs(null_difs))
sort(abs(null_difs))
reps <- 5000
null_difs <- numeric(reps)
for (i in 1:reps){
newindices <- sample(c(1:nrow(reshape_df)))
newGroup <- reshape_df$Group[newindices]
dif <- mean(reshape_df$Mass[newGroup=="A"])	- mean(reshape_df$Mass[newGroup=="B"])
null_difs[i] <- dif
}
hist(null_difs)
hist(null_difs)
abline(v=observed_dif,col="green",lwd=3)
reps <- 5000
null_difs <- numeric(reps)
for(i in 1:reps){
sampleA <- sample(popData_null,size=sample.size)
sampleB <- sample(popData_null,size=sample.size)
null_difs[i] <- mean(sampleA)-mean(sampleB)
}
hist(null_difs)
abline(v=observed_dif,col="green",lwd=3)
hist(null_difs)
abline(v=observed_dif,col="green",lwd=3)
ordered_difs <- sort(abs(null_difs))
higher_anomaly <- length(which(ordered_difs>=abs(observed_dif)))
p_value <- higher_anomaly/reps
p_value
reps <- 5000
null_difs <- numeric(reps)
for (i in 1:reps){
newindices <- sample(c(1:nrow(reshape_df)))
newGroup <- reshape_df$Group[newindices]
dif <- mean(reshape_df$Mass[newGroup=="A"])	- mean(reshape_df$Mass[newGroup=="B"])
null_difs[i] <- dif
}
hist(null_difs)
abline(v=observed_dif,col="green",lwd=3)
hist(null_difs)
abline(v=observed_dif,col="green",lwd=3)
abs(null_difs)
higher_anomaly <- length(which(abs(null_difs)>=abs(observed_dif)))
p_value <- higher_anomaly/reps
p_value
reps <- 1000
null_difs <- numeric(reps)
for(i in 1:reps){
sampleA <- sample(popData_null,size=sample.size)
sampleB <- sample(popData_null,size=sample.size)
null_difs[i] <- mean(sampleA)-mean(sampleB)
}
hist(null_difs)
abline(v=observed_dif,col="green",lwd=3)
ordered_difs <- sort(abs(null_difs))
higher_anomaly <- length(which(ordered_difs>=abs(observed_dif)))
p_value <- higher_anomaly/reps
p_value
reps <- 1000
null_difs <- numeric(reps)
for(i in 1:reps){
sampleA <- sample(popData_null,size=sample.size)
sampleB <- sample(popData_null,size=sample.size)
null_difs[i] <- mean(sampleA)-mean(sampleB)
}
hist(null_difs)
abline(v=observed_dif,col="green",lwd=3)
ordered_difs <- sort(abs(null_difs))
higher_anomaly <- length(which(ordered_difs>=abs(observed_dif)))
p_value <- higher_anomaly/reps
p_value
reps <- 1000
null_difs <- numeric(reps)
for(i in 1:reps){
sampleA <- sample(popData_null,size=sample.size)
sampleB <- sample(popData_null,size=sample.size)
null_difs[i] <- mean(sampleA)-mean(sampleB)
}
hist(null_difs)
abline(v=observed_dif,col="green",lwd=3)
ordered_difs <- sort(abs(null_difs))
higher_anomaly <- length(which(ordered_difs>=abs(observed_dif)))
p_value <- higher_anomaly/reps
p_value
library(help = "datasets")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
c(1,0.01,5,0.5)
probs <- c(1,0.01,5,0.5)
probs <- probs/sum(probs)
n=100
apply(rmultinom(n,1,probs),2,function(t) which(t==1))
rlocodist <- function(n){
vals <- c(4,7,10,500)
probs <- c(1,0.01,5,0.5)
probs <- probs/sum(probs)
vals[apply(rmultinom(n,1,probs),2,function(t) which(t==1))]
}
lots=10000
datafountain <- rlocodist(lots)
hist(datafountain)
rlocodist <- function(n){
vals <- c(4,7,10,50)
probs <- c(1,0.01,5,0.5)
probs <- probs/sum(probs)
vals[apply(rmultinom(n,1,probs),2,function(t) which(t==1))]
}
lots=10000
datafountain <- rlocodist(lots)
hist(datafountain)
rlocodist <- function(n){
vals <- c(1,7,10,35)
probs <- c(1,0.01,5,0.5)
probs <- probs/sum(probs)
vals[apply(rmultinom(n,1,probs),2,function(t) which(t==1))]
}
lots=10000
datafountain <- rlocodist(lots)
hist(datafountain)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
n_red <- 104
n_blue <- 55
allSpheres <- c(n_red,n_blue,n_green)
names(allSpheres) <- c("red","blue","green")
n_red <- 104
n_blue <- 55
n_green <- 30
allSpheres <- c(n_red,n_blue,n_green)
names(allSpheres) <- c("red","blue","green")
allSpheres
P_blue <- allSpheres["blue"]/sum(allSpheres)
P_blue
Probs <- allSpheres/sum(allSpheres)
Probs
Probs["blue"] + Probs["red"]
Probs["blue"] + Probs["red"]
Probs["blue"]
Probs["red"]
Probs["blue"] * Probs["red"]
as.numeric( Probs["blue"] * Probs["red"] )
as.numeric( Probs["blue"] + Probs["red"] )
as.numeric( (Probs["blue"] * Probs["red"]) + (Probs["red"] * Probs["blue"]) )
as.numeric( Probs["blue"] + Probs["red"] + Probs["green"] )
n_red_sphere <- 39
n_blue_sphere <- 76
n_red_cube <- 101
n_blue_cube <- 25
allSpheres <- c(n_red_sphere,n_blue_sphere)
allCubles <- c(n_red_cube,n_blue_cube)
allSpheres <- c(n_red_sphere,n_blue_sphere)
allCubes <- c(n_red_cube,n_blue_cube)
allTypes <- c(allSpheres,allCubes)
allTypes
Shape <- c(sum(allSpheres),sum(allCubes))/sum(allTypes)
Shape
names(Shape) <- c("sphere","cube")
Shape
allSpheres <- c(n_red_sphere,n_blue_sphere)
allCubes <- c(n_red_cube,n_blue_cube)
allTypes <- c(allSpheres,allCubes)
allTypes <- matrix(allTypes,nrow=2,ncol=2,byrow=T)
allTypes
rownames(allTypes) <- c("sphere","cube")
colnames(allTypes) <- c("red","blue")
allTypes
allSpheres <- c(n_red_sphere,n_blue_sphere)
allCubes <- c(n_red_cube,n_blue_cube)
allTypes <- c(allSpheres,allCubes)
allTypes <- matrix(allTypes,nrow=2,ncol=2,byrow=T)
rownames(allTypes) <- c("sphere","cube")
colnames(allTypes) <- c("red","blue")
allTypes
Shape <- apply(allTypes,1,sum)/sum(allTypes)
Shape
Color <- c(sum(allSpheres),sum(allCubes))/sum(allTypes)
names(allSpheres) <- c("red","blue","green")
Prob_Shape
Prob_Shape <- apply(allTypes,1,sum)/sum(allTypes)
Prob_Shape
Prob_Color <- apply(allTypes,2,sum)/sum(allTypes)
Prob_Color
Prob_Color["red"]
as.numeric( Prob_Color["blue"] + Prob_Shape["cube"])
as.numeric( Prob_Color["blue"] + Prob_Shape["cube"] - (Prob_Color["blue"] * Prob_Shape["cube"])  )
allTypes
allTypes/sum(allTypes)
as.numeric( Prob_Color["blue"] * Prob_Shape["cube"])
allTypes/sum(allTypes)["cube","blue"]
allTypes/sum(allTypes)
(allTypes/sum(allTypes))["cube","blue"]
as.numeric( Prob_Color["blue"] + Prob_Shape["cube"] - (Prob_Color["blue"] * Prob_Shape["cube"])  )
allTypes/sum(allTypes))["cube","blue"] / Prob_Shape["cube"])
allTypes/sum(allTypes))["cube","blue"]
(allTypes/sum(allTypes))["cube","blue"] / Prob_Shape["cube"])
(allTypes/sum(allTypes))["cube","blue"] / Prob_Shape["cube"]
(allTypes/sum(allTypes))["cube","blue"]
(allTypes/sum(allTypes))["cube","blue"]
(allTypes/sum(allTypes))["cube","blue"] / Prob_Shape["cube"]
allTypes
allTypes/sum(allTypes)
0.1/0.41
(allTypes/sum(allTypes))["cube","blue"] / Prob_Shape["cube"]
Prob_Shape["cube"]
as.numeric( Prob_Color["blue"] * Prob_Shape["cube"]) / Prob_Shape["cube"]
allTypes["cube",]
allTypes["cube",]/sum(allTypes["cube",])
(allTypes/sum(allTypes))["cube","blue"] / Prob_Shape["cube"]
Prob_Color["blue"] * (allTypes/sum(allTypes))["cube","blue"] / Prob_Shape["cube"]
as.numeric( Prob_Color["blue"] * (allTypes/sum(allTypes))["cube","blue"] / Prob_Shape["cube"] )
(allTypes/sum(allTypes))["cube","blue"]
as.numeric( Prob_Color["blue"] * (allTypes/sum(allTypes))["cube","blue"] / Prob_Shape["blue"] )
as.numeric( Prob_Color["blue"] * (allTypes/sum(allTypes))["cube","blue"] / Prob_Color["blue"] )
allTypes
as.numeric( (allTypes/sum(allTypes))["cube","blue"] / Prob_Shape["cube"] + (allTypes/sum(allTypes))["sphere","blue"] / Prob_Shape["sphere"])
apply(allTypes),2,sum)
apply(allTypes,2,sum)
as.numeric( ((allTypes/sum(allTypes))["cube","blue"] / Prob_Shape["cube"]) * Prob_Shape["cube"] +
((allTypes/sum(allTypes))["sphere","blue"] / Prob_Shape["sphere"]) * Prob_Shape["sphere"]  )
apply(allTypes,2,sum)
101/(140+101)
Prob_Disease <- c(1,999999)
Prob_Disease <- Prob_Disease/sum(Prob_Disease)
Prob_Disease
names(Prob_Disease) <- c("yes","no")
Prob_Disease
1*Prob_Disease["yes"]
1*Prob_Disease["yes"] + 0.01*Prob_Disease["no"]
as.numeric( 1*Prob_Disease["yes"] + 0.01*Prob_Disease["no"] )
