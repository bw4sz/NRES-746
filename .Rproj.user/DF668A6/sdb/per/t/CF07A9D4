{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Lecture #1\"\nauthor: \"NRES 746\"\ndate: \"August 23, 2016\"\noutput: \n  html_document: \n    theme: cerulean\n    toc: yes\n    toc_float: yes\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, cache = TRUE)\n```\n\n```{r include=FALSE}\nlibrary(dplyr)\nlibrary(tidyr)\n```\n\n\n## Algorithmic vs standard statistics: a brief demonstration\n\n### standard t test\n\nFirst, let's go through a very basic review.   \n\nHere is a made-up data set. Let's imagine we are interested in seeing if the average height of study organisms in Group A are different from those in Group B.  \n\n```{r}\n\ndata <- data.frame(\n  GroupA = c(175, 168, 168, 190, 156, 181, 182, 175, 174, 179),\n  GroupB = c(185, 169, 173, 173, 188, 186, 175, 174, 179, 180) \n)\n\nsummary(data)\n\nsample.size <- length(data$GroupA)\n\nreshape_data <- data.frame(\n  Group = rep(c(\"A\",\"B\"),each=sample.size),\n  Height = c(data$GroupA,data$GroupB)\n)\n\nplot(Height~Group, data=reshape_data)\n\nobserved_dif <- mean(data$GroupA) - mean(data$GroupB)\nobserved_dif\n\n```\n\nYou probably recognize the standard t-test below. For now, we are assuming that the samples come from normally distributed populations with equal variances. \n\n```{r}\nt.test(data$GroupA,data$GroupB, var.equal=TRUE, paired=FALSE)\n\n```\n\nBut let's imagine now that we didn't know about the t-test- but we still want to accomplish the same goal.  \n\nFirst, let's review the question and state the problem clearly:\n\nWe want to know if these two populations are different- specifically if the expected value (mean) differs. We have small random (but representative) samples from these two putative populations.  \n\nCan we build an **algorithm** to generate a p-value? \n\nLet's start by simulating a data population under the null hypothesis. \n\n```{r}\nlots <- 1000000  # large number approximating infinity in this example!\n\npopMean_null <- mean(reshape_data$Height)        # assume groups A and B come from a population with common mean \npopSD_null <- sd(reshape_data$Height)\npopData_null <- rnorm(n=lots,mean=popMean_null,sd=popSD_null)    # the statistical \"population\" of interest (under null model)\n\n```\n\nThen we can sample from that data population:\n\n```{r}\nsampleA <- sample(popData_null,size=sample.size)   \nsampleB <- sample(popData_null,size=sample.size)\n\nsampleA\ndifference <- mean(sampleA)-mean(sampleB)   # difference between sample means\n\n```\n\nThen we can generate a distribution of \"anomalies\" (differences between the group means) expected under the null hypothesis (there is fundamentally no difference between the two groups):\n\n```{r}\nreps <- 1000\nnull_difs <- numeric(reps)\n\nfor(i in 1:reps){\n  sampleA <- sample(popData_null,size=sample.size)   \n  sampleB <- sample(popData_null,size=sample.size)\n  null_difs[i] <- mean(sampleA)-mean(sampleB)\n}\n\nhist(null_difs)\nabline(v=observed_dif,col=\"green\",lwd=3)\n\n```\n\n\nNow, all we need to do is compare this more quantitatively with the observed among-group difference...\n\n```{r}\n  ordered_difs <- sort(abs(null_difs))   # first order the distribution of null results in terms of absolute magnitude of difference\n  higher_anomaly <- length(which(ordered_difs>=abs(observed_dif)))\n  p_value <- higher_anomaly/reps   # probability of getting a value with anomaly as or more extreme than observed, given null hypothesis is true...\n  p_value\n\n```\n\n\n### Exercise (intermediate)\nRepeat the same exercise, but using a different underlying distribution- say, the binomial or the Poisson. Compare with a standard t-test. Which test do you trust more?\n\n### Exercise (intermediate)\nModify the above algorithm to allow for unequal sample sizes. Compare with a standard t-test. Can you identify any cases where the t-test results differ substantially from your algorithmic results? \n\n### Exercise (advanced)\nNow, what about if we wanted to relax the assumption of equal variances? How would you modify the above algorithm to do this?  \n\n### Take-home message\nThe value of the algorithmic, brute-force approach to statistics is the flexibility! We have to be aware of assumptions in all of our analyses, but when we have some computational tools at hand, we can readily relax these assumptions. \n\n--------------------------------\n## Bootstrapping a confidence interval\n\n(NOTE: some materials borrowed from [link](http://people.tamu.edu/~alawing/materials/ESSM689/Btutorial.pdf))\n\nLet's imagine we want to compare different predictor variables in terms of how strong the relationship is with a response variable. In this case, we will use the coefficient of determination ($R^2$) as a measure of how good a predictor is. However, we want to be able to say that one predictor is definatively *better* than another one -- for that, we would like a confidence interval around the $R^2$ value.\n\nLet's use the \"trees\" dataset provided in base R:\n\n```{r}\nhead(trees)   # use help(trees) for more information\n\n```\n\nLet's say that tree volume is our response variable. We want to see if girth or height are better predictors of volume. \n\nLet's first do some basic data explorations:\n\n```{r}\nplot(trees$Volume~trees$Height, main = 'Black Cherry Tree Height/Volume Relationship', xlab = 'Height', ylab = 'Volume', pch = 16, col ='blue')\nplot(trees$Volume~trees$Girth, main = 'Black Cherry Tree Girth/Volume Relationship', xlab = 'Girth', ylab = 'Volume', pch = 16, col ='red')\n```\n\n\nLet's write a simple function that generates coefficients of determination given a response and some predictor variables:\n\n```{r}\n\nRsquared <- function(df,responsevar=\"Volume\"){    # interactions not yet implemented\n  response <- df[,responsevar]\n  names <- names(df)\n  rsq <- numeric(length(names))\n  names(rsq) <- names(df)\n  rsq <- rsq[names(rsq)!=responsevar]\n  for(i in names(rsq)){         # loop through predictors\n      predictor <- df[,i]\n      model <- lm(response~predictor)  \n      rsq[i] <- summary(model)$r.square \n  }\n  return(rsq)\n}\n\n```\n\n\nLet's first compute the Rsquared values for all predictor variables:\n\n```{r}\nstat <- Rsquared(trees,\"Volume\")\nstat\n\n```\n\n\nNow we can use \"bootstrapping\" to generate a confidence interval around these values...\n\nLet's first write a function to generate bootstrap samples from a dataset:\n\n```{r}\n\nboot_sample <- function(df,statfunc,n_samples,n_stats){\n  indices <- c(1:nrow(df))\n  output <- matrix(NA,nrow=n_samples,ncol=n_stats)\n  for(i in 1:n_samples){\n    boot_rows <- sample(indices,size=nrow(df),replace=T)\n    newdf <- df[boot_rows,]\n    output[i,] <- statfunc(newdf)\n  }\n  return(output)\n}\n\n```\n\nNow we can generate a bunch of \"bootstrapped\" statistics to compare with the ones calculated from the full dataset:\n\n```{r}\nboot <- boot_sample(trees,Rsquared,10,length(stat))\ncolnames(boot) <- names(stat)\n\nboot\nstat\n\n```\n\nFinally, we can use the quantiles of the bootstrap samples to generate bootstrap confidence intervals.\n\n```{r}\nboot <- boot_sample(trees,Rsquared,1000,length(stat))   # 1000 bootstrap samples\nconfint <- apply(boot,2,function(t)  quantile(t,c(0.025,0.5,0.975)))\ncolnames(confint) <- names(stat)\nt(confint)\nquantile(boot,c(0.025,0.975))\n\n```\n\n\n\n\n### Exercise (intermediate):\nGenerate bootstrap confidence intervals around the regression parameters. Compare with the standard confidence intervals given by R in the \"lm\" package.\n\n\n### Exercise (advanced):\nModify the algorithm above to select the top model from among all possible models (including interaction terms)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "created" : 1471975581739.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1721185990",
    "id" : "CF07A9D4",
    "lastKnownWriteTime" : 1472164585,
    "last_content_update" : 1472165334302,
    "path" : "E:/GIT/NRES-746/LECTURE1.Rmd",
    "project_path" : "LECTURE1.Rmd",
    "properties" : {
        "last_setup_crc32" : "232184497d023e20"
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}