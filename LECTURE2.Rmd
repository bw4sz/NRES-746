---
title: "Working with Probabilities"
author: "NRES 746"
date: "August 31, 2016"
output: 
  html_document: 
    theme: cerulean
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

Note: some materials borrowed from White and Morgan's "STATISTICAL MODELS IN ECOLOGY USING R" course

In the last class, we reviewed basic programming in R, using basic constructs like the programming loop (e.g., "for", "while") and random sampling (e.g., using the 'sample' function in R) to build our own analyses from first principles. We began the course this way because the ability to understand, use, and build algorithms is absolutely fundamental to modern data analysis.

Also fundamental to modern data analysis is an ability to work with probabilities. Again, many of you will find this a very basic review, but I really want to ensure that all of us are working with solid foundations before we venture into more advanced topics.

The central points:
    * Most traditional statistics utilize tricks & assumptions to ensure the data follow a particular distribution (usually normal)
    * With more computational power, we are much less limited and can model alternative distributions more easily



## Basic probability rules

### Classic Urn Example 

Consider an Urn filled with blue, red, and green spheres. To make the example more concrete, assume the following:
    * red: 104
    * blue: 55
    * green: 30

```{r}
n_red <- 104
n_blue <- 55
n_green <- 30

allSpheres <- c(n_red,n_blue,n_green)
names(allSpheres) <- c("red","blue","green")

```

What is the probability of drawing a blue sphere?

```{r}
P_blue <- allSpheres["blue"]/sum(allSpheres)
P_blue

```

Let's generate a vector of probabilities for drawing each type of sphere...

```{r}

Probs <- allSpheres/sum(allSpheres)
Probs

```


What is the probability of drawing a blue **OR** a red sphere?

```{r}
as.numeric( Probs["blue"] + Probs["red"] )
```

What is the probability of drawing a blue **OR** a red sphere **OR** a green sphere?

```{r}
as.numeric( Probs["blue"] + Probs["red"] + Probs["green"] )
```

What would it mean if this didn't sum to 1?

What is the probability of drawing a blue **AND THEN** a red sphere?

```{r}
as.numeric( Probs["blue"] * Probs["red"] )
```

What is the probability of drawing a blue and a red in two consecutive draws?

```{r}
as.numeric( (Probs["blue"] * Probs["red"]) + (Probs["red"] * Probs["blue"]) )
```


### Less-classic urn example

Now consider an urn filled with blue & red objects of two types: spheres & cubes. To make the example more concrete, assume the following:
    * red sphere: 39
    * blue sphere: 76
    * red cube: 101
    * blue cube: 25

```{r}
n_red_sphere <- 39
n_blue_sphere <- 76
n_red_cube <- 101
n_blue_cube <- 25

allSpheres <- c(n_red_sphere,n_blue_sphere)
allCubes <- c(n_red_cube,n_blue_cube)
allTypes <- c(allSpheres,allCubes)
allTypes <- matrix(allTypes,nrow=2,ncol=2,byrow=T)
rownames(allTypes) <- c("sphere","cube")
colnames(allTypes) <- c("red","blue")
allTypes

Prob_Shape <- apply(allTypes,1,sum)/sum(allTypes)
Prob_Shape

Prob_Color <- apply(allTypes,2,sum)/sum(allTypes)
Prob_Color

```

What is the *marginal probability* of drawing a red object (and why do we call it a "marginal" probability?)

```{r}
Prob_Color["red"]
```

What is the *joint probability* of drawing an object that is both blue AND a cube?

```{r}
as.numeric( Prob_Color["blue"] * Prob_Shape["cube"])  

```

Is this correct? If not, why?

Under what circumstances would this be correct?

What is the correct answer?

```{r}
(allTypes/sum(allTypes))["cube","blue"]   
```

What is the probability of drawing an object that is blue **OR** a cube?   $Prob(blue)\bigcup Prob(cube)$

```{r}
as.numeric( Prob_Color["blue"] + Prob_Shape["cube"])  

```

Is this correct? If not, why?

What is the correct answer?

```{r echo=FALSE}
as.numeric( Prob_Color["blue"] + Prob_Shape["cube"] - (Prob_Color["blue"] * Prob_Shape["cube"])  )  
```


```{r echo=FALSE}
as.numeric( Prob_Color["blue"] + Prob_Shape["cube"] - (Prob_Color["blue"] * Prob_Shape["cube"])  )  
```


What is the **conditional probability** of getting a blue object, given that it is a cube?    $Prob(blue|cube)$

This can be expressed as:  $Prob(blue|cube) = Prob(blue,cube) / Prob(cube)$

```{r}
(allTypes/sum(allTypes))["cube","blue"] / Prob_Shape["cube"]

```


Can we now express the joint probability of drawing a blue cube in terms of conditional probabilities?

Prob(blue) \bigcap Prob(cube) = Prob(blue) * Prob(cube|blue)

Does this now give us the correct answer?

```{r}
as.numeric( Prob_Color["blue"] * (allTypes/sum(allTypes))["cube","blue"] / Prob_Color["blue"] )

```


## Frequentism vs. Bayesianism
Two types of conditional probabilities:
P(data|hypothesis) is a likelihood – the probability of getting our data, given a particular
hypothesis. Frequentists use this approach. Given a null hypothesis, what is the
probability of getting these data (or data more extreme) - this is the definition of a pvalue.
The likelihood is understood in terms of long-term frequencies – if we collected
similar data many, many times, what fraction of the time would we get the outcome we
observed (if the null hypothesis is true)? Developed by Fisher & contemporaries.
P(hypothesis|data) is called a posterior probability. It is the probability of getting our
hypothesis, given the data we collected. This is how we usually interpret likelihoods and
p-values, but the two things are not the same! Bayesians use posteriors, and they feel
superior because P(hypothesis|data) is what we all really want to know, anyway.
However, Frequentists make fun of Bayesians for doing this, because there are some
potential problems in the Bayesian approach. Do not underestimate the vitriol between
Frequentists and Bayesians. Also note that the seriousness with which people commit to
one side or the other often corresponds to a propensity to show up at a conference
wearing shorts of an improperly small size (this is a good example of a conditional
probability).
As a shorthand, we will often write likelihoods as P(X|θ) or L(X| θ) or L(θ) (you have to
use LaTex to make the funny L symbol that Bolker uses) and posteriors as P(θ |X).
To use posteriors, we use Bayes’ Law:
P(θ|X) = P(X|θ) P(θ)/ P(X)
That is: posterior = likelihood × prior / denominator
Bayes’ Law is not constroversial. What is controversial is that Bayesians plug in the
prior probability of the hypothesis, P(θ). This is often interpreted as the a priori
expectation of a particular state of nature, and can be somewhat subjective. It’s this
subjectivity that is controversial. The other tricky thing about Bayes’ Law is the
denominator, which requires summing up the probability of all possible ways of getting
the data. This is easy when there is a fairly discrete set of hypotheses (as in the Monty
Hall example) but gets harder in other cases. Markov chain – Monte Carlo techniques
were essentially invented to calculate the denominator in Bayes’ Law.
* Note that I think I switched the prior and denominator when I wrote up Bayes Law on
the boad
4. Example of using probability and Bayes’ Law: Let’s Make a Deal
The setup: 3 doors, 1 hides a prize and the other hide goats or donkeys or yaks or
something that would be desirable in Tashkent but not in Boca Raton. You pick door A.
Before you see what’s behind door A, the host, Monty Hall, opens door C to reveal a
goat. Now you can stay with A or switch to door B. Should you switch? Note that no
matter what door you choose at first, Monty will always open one of the other doors, and
will never open the door with the prize (he knows where the prize is).
To do this we want to know P(X|I) and P(B|I), where X = the door is behind door X, and
I = the information that you picked door A and Monty showed you the goat behind door
C.
First, calculate the priors: P(A) = P(B) = P(C) = 1/3
Now, the likelihoods.
P(I|A) = ½, because if the prize is behind door A, Monty can show you either door B or
door C. So the likelihood of the data (he shows you door C) given the hypothesis (the
prize is behind door A) is only ½.
P(I|A) = 1, because if the prize is behind door B, Monty can only show you what’s
behind door C. It is the only option available to him. In other words, the likelihood of
the data (he shows you door C) given the hypothesis (the prize is behind door B) is 1.
Now we need the denominator, P(I). The easiest way to get this unconditional
probability is to rearrange the equation for conditional probability:
P(X,I) = P(I|X)P(X)
so P(I) = all possible ways of getting P(I):
P(I) = P(I|A)P(A) + P(I|B)P(B) + P(I|C)P(C)
(either A is true and you observe I, or B is true and you observe I, or C is true and you
observe I).
P(I) = ½ × 1/3 + 1 × 1/3 + 0 × 1/3 = ½
So put it all together:
P(A|I) = (1/2) ×(1/3)/(1/2) = 1/3
P(B|I) = (1) ×(1/3)/(1/2) = 2/3
So it is always better to switch. I have posted some R code on the webpage that
simulates this game to confirm this result.
Notice that in this case, the ratio of the two likelihoods (1 to 1/2) was the same as the
ratio of the two posteriors (2/3 to 1/3). This is true only because the priors were all the
same (this would be called “flat” or “uninformative” priors). However, if we had more
prior information – say, there was a strong smell of goat coming from door A, then the
priors would be different ( P(A) > P(B) ). The likelihoods would remain exactly the
same, but the posterior for A would be greater than 1/3. That’s the value of the Bayesian
approach – it can combine all available information.
5. Features of probability distributions
Discrete vs. continuous
In discrete distributions, each outcome has a specific probability ( like the probability of
flipping a coin 10 times and getting 4 heads). In continuous distributions, the height of
the curve corresponds to probability density, f(x), not probability P(x). This is because
the probability of getting exactly one value in a continuous distribution is effectively
zero. This arises from the problem of precision. The sum of the probability distribution
must be 1 (there is only 100% of probability to go around). So the sum of all P(x) must
be 1. But in a continuous distribution, there are an infinite number of values of x (think
about it – between x = 2.01 and x = 2.02 are the numbers 2.001, 2.002, 2.003, ..., and
between those are 2.0001, 2.0002, 2.0003, ... The number line is infinitely divisible). So
any individual probability is always divided by infinity, which makes it zero. The long
and short of this is that we have to talk about probability density, unless we want to
specify a particular range of values – we can’t calculate P(x = 5), but we can calculate
P(4 < x < 6) or P(x > 5).
For this reason, when dealing with continuous distributions, the likelihood P(θ|H) will
have to be a probability density f(θ|H). So likelihoods are not always probabilities.
Some other distributional lingo:
Moments – descriptions of the shaped & central tendency of the distribution
Parameters – the values in the probability distribution function that define the shape of
the pdf. Parametric statistics require assuming certain things about distributions &
parameters, while nonparametric stats do not require these assumptions.
6. Some probability distributions
Most of the distributions we use were originally formulated in industrial applications and
then rejiggered for ecology. That’s why most of them deal with waiting times, failures,
etc. Bolker explains the main ones. Pay particular attention to the type of process
described by each distribution. The key to using these correctly is to figure out which
statistical process best matches the ecological process you’re studying, then use that
distribution. e.g., Am I observing independent, random events occurring in a fixed
window of time or space (like sampling barnacles in quadrats on an intertidal bench)?
Then the distribution of their occurrence probably follows a Poisson distribution.