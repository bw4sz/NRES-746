---
title: "Working with Probabilities"
author: "NRES 746"
date: "August 31, 2016"
output: 
  html_document: 
    theme: cerulean
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

Note: some materials borrowed from White and Morgan's "STATISTICAL MODELS IN ECOLOGY USING R" course

In the last class, we reviewed basic programming in R, using basic constructs like the programming loop (e.g., "for", "while") and random sampling (e.g., using the 'sample' function in R) to build our own analyses from first principles. We began the course this way because the ability to understand, use, and build algorithms is absolutely fundamental to modern data analysis.

Also fundamental to modern data analysis is an ability to work with probabilities. Again, many of you will find this a very basic review, but I really want to ensure that all of us are working with solid foundations before we venture into more advanced topics.

The central points:
    * Most traditional statistics utilize tricks & assumptions to ensure the data follow a particular distribution (usually normal)
    * With more computational power, we are much less limited and can model alternative distributions more easily



## Basic probability rules

### Classic Urn Example 

Consider an Urn filled with blue, red, and green spheres. To make the example more concrete, assume the following:
    * red: 104
    * blue: 55
    * green: 30

```{r}
n_red <- 104
n_blue <- 55
n_green <- 30

allSpheres <- c(n_red,n_blue,n_green)
names(allSpheres) <- c("red","blue","green")

```

What is the probability of drawing a blue sphere?

```{r}
P_blue <- allSpheres["blue"]/sum(allSpheres)
P_blue

```

Let's generate a vector of probabilities for drawing each type of sphere...

```{r}

Prob <- allSpheres/sum(allSpheres)
Prob

```


What is the probability of drawing a blue **OR** a red sphere?

```{r}
as.numeric( Prob["blue"] + Prob["red"] )
```

What is the probability of drawing a blue **OR** a red sphere **OR** a green sphere?

```{r}
as.numeric( Prob["blue"] + Prob["red"] + Prob["green"] )
```

What would it mean if this didn't sum to 1?

What is the probability of drawing a blue **AND THEN** a red sphere?

```{r}
as.numeric( Prob["blue"] * Prob["red"] )
```

What is the probability of drawing a blue and a red in two consecutive draws?

```{r}
as.numeric( (Prob["blue"] * Prob["red"]) + (Prob["red"] * Prob["blue"]) )
```


### Less-classic urn example

Now consider an urn filled with blue & red objects of two types: spheres & cubes. To make the example more concrete, assume the following:

* red sphere: 39
* blue sphere: 76
* red cube: 101
* blue cube: 25

```{r}
n_red_sphere <- 39
n_blue_sphere <- 76
n_red_cube <- 101
n_blue_cube <- 25

allSpheres <- c(n_red_sphere,n_blue_sphere)
allCubes <- c(n_red_cube,n_blue_cube)
allTypes <- c(allSpheres,allCubes)
allTypes <- matrix(allTypes,nrow=2,ncol=2,byrow=T)
rownames(allTypes) <- c("sphere","cube")
colnames(allTypes) <- c("red","blue")
allTypes

Prob_Shape <- apply(allTypes,1,sum)/sum(allTypes)
Prob_Shape

Prob_Color <- apply(allTypes,2,sum)/sum(allTypes)
Prob_Color

```

What is the *marginal probability* of drawing a red object (and why do we call it a "marginal" probability?)

```{r}
Prob_Color["red"]
```

What is the *joint probability* of drawing an object that is both blue AND a cube?

```{r}
as.numeric( Prob_Color["blue"] * Prob_Shape["cube"])  

```

Is this correct? If not, why?

Under what circumstances would this be correct?

What is the correct answer?

```{r}
(allTypes/sum(allTypes))["cube","blue"]   
```

What is the probability of drawing an object that is blue **OR** a cube?   $Prob(blue\bigcup cube)$

```{r}
as.numeric( Prob_Color["blue"] + Prob_Shape["cube"])  

```

Is this correct? If not, why?

What is the correct answer?

```{r echo=FALSE}
as.numeric( Prob_Color["blue"] + Prob_Shape["cube"] - (Prob_Color["blue"] * Prob_Shape["cube"])  )     # not mutually exclusive
```


```{r echo=FALSE}
as.numeric( Prob_Color["blue"] + Prob_Shape["cube"] - (Prob_Color["blue"] * Prob_Shape["cube"])  )  
```


What is the **conditional probability** of getting a blue object, given that it is a cube?    $Prob(blue|cube)$

This can be expressed as:  $Prob(blue|cube) = Prob(blue,cube) / Prob(cube)$

```{r}
(allTypes/sum(allTypes))["cube","blue"] / Prob_Shape["cube"]

```


Can we now express the joint probability of drawing a blue cube in terms of conditional probabilities?

$Prob(blue\bigcap cube) = Prob(blue) * Prob(cube|blue)$

Does this now give us the correct answer?

```{r}
as.numeric( Prob_Color["blue"] * (allTypes/sum(allTypes))["cube","blue"] / Prob_Color["blue"] )

```

What is an unconditional probability?

What is the unconditional probability of drawing a blue item, regardless of shape?

$Prob(blue|male)\cdot Prob(male) + Prob(blue|not male) \cdot Prob(not male)$  

```{r}
as.numeric( ((allTypes/sum(allTypes))["cube","blue"] / Prob_Shape["cube"]) * Prob_Shape["cube"] + 
              ((allTypes/sum(allTypes))["sphere","blue"] / Prob_Shape["sphere"]) * Prob_Shape["sphere"]  )
```

#### Short exercise #1
Can you interpret the above equation in words? Take a moment to try!
How does this relate to the marginal probability?   

#### Short exercise #2
What does it mean if the conditional probability of drawing a blue object (e.g., given it is a cube) is equal to the unconditional probability of drawing a blue item?
Can we say anything about the relationship or dependency among color and shape in this example?

### Bolker's medical example

Suppose the infection rate (prevalence) for a rare disease is one in a million:

```{r}
Prob_Disease <- c(1,999999)     # disease prevalence 
Prob_Disease <- Prob_Disease/sum(Prob_Disease)
names(Prob_Disease) <- c("yes","no")
Prob_Disease
```

Suppose there is a test that never gives a false negative (if you've got it you will test positive) but very rarely gives a false positive result (if you ain't got it, you might still test positive for the disease). Let's imagine the false positive rate is 1%. 

Medical professionals (and patients!) often want to know the probability that a positive-testing patient actually has the disease. This quantity is known as the *Positive Predictive Value* or PPV. How can we compute this?

Stated another way, we want to know the *conditional probability* of having the disease given a positive test result.

$Prob(Disease|+test)$   

What do we have already?  

First of all, we know the conditional probability of having a positive test result given the patient has the disease

$Prob(+test|Disease) = 1$  

Secondly, we know the conditional probability of having a positive test result given the patient doesn't have the disease

$Prob(+test|no Disease) = 0.01$

Third, we know the unconditional probability of having the disease

$Prob(Disease) = 0.000001$   

Now, can we use basic probability rules to compute the PPV?  

What is the unconditional probability of testing positive? 

$Prob(+test)$  

We can either test positive and have the disease or we can test positive and not have the disease...

$Prob(+test\bigcap Disease) + Prob(+test\bigcap no Disease)$   

Stated another way,     

$Prob(+test|Disease)*Prob(Disease) + Prob(+test|no Disease)*Prob(no Disease)$


```{r}

as.numeric( 1*Prob_Disease["yes"] + 0.01*Prob_Disease["no"] )

```

So now we have $Prob(+test|Disease)$, $Prob(Disease)$, and $Prob(+test)$. How can we use these components to compute $Prob(Disease|+test)$? 


#### Short exercise 3
What's the the *joint probability* of being infected and testing positive?

What's the PPV??

Re-structure your PPV equation so that you consider the positive test result to be the "Data" and the positive disease status to be the "Hypothesis"  

The equation you just generated is known as **Bayes' theorem** (or Bayes' rule). It forms the basis for **Bayesian statistics**

How does this simple rule of probability relate to Bayesian statistics??

## Frequentism vs. Bayesianism (an aside)

### What is Frequentism?
Under this paradigm, the true answers are hidden behind a veil of sampling variability. That is, if we had perfect knowledge (infinite sample size) we would know the answers we seek. Random sampling errors prevent this level of certainty. However, if we know the *frequency* with which random sampling yields anomalies of various magnitudes, then we can understand and control for the effects of sampling variability. For example, we can set an $\alpha$ level (false-positive rate that we can live with) and then make a "positive" conclusion about a test only if random sampling variability could account for the observed effect size with a frequency at or below the pre-determined $\alpha$ level.     

### What is Bayesianism
In many ways, Bayesian analyses can interpreted in the way that many of us intuitively *want* to interpret statistics-- as probabilities. Given a set of plausible models for describing a system, Bayesian statistics can tell us the probability that model A is the model that generated the observed data. If we fit a regression model, Bayesian statistics can tell us the probability that the true regression parameter $\beta_{1}$ is above zero. That said, Bayesian analyses require specifying a *prior* probability on all fitted parameters and models. This can pose a philosophical problem: what if you don't have any prior knowledge? Furthermore, the interpretation of *probability* itself can get us in philosophical trouble here, because Bayesian probabilities are best interpreted as a "degree of belief" (scaled to sum to 1). Interpreted in this way, your conclusions from the same data could be very different from mine... But at least these differences could be stated formally in terms of different prior distributions!

### Which paradigm is better?
The pragmatic analyst admits that they are both useful, and uses both methods freely!! 

#### Short exercise 4
**Likelihood** is defined as: $Prob(data|model)$. Is the notion of a likelihood inherently Bayesian or Frequentist?

![](frequentists_vs_bayesians.png)

#### Short exercise 5
As you can see, Bayes theorem can be derived by simple probability rules. Why is it so controversial?

## Let's make a deal!
The setup: you are in a game show, called *Let's Make a Deal*! There are three doors in front of you. One hides a prize and the other hides goats. 

![Monty Hall problem, setup](montyhall.jpg)

You pick door A. Before you see what’s behind door A, the host, Monty Hall, opens door C to reveal a goat. Now you can stay with A or switch to door B. Should you switch? NOTE: no matter what door you choose at first, Monty will always open one of the other doors, and will never open the door with the prize (he knows where the prize is). ALSO NOTE: you can't keep the goat even if you want it!

Given the new info, we now know that the prize isn't behind door C. We want to know $Prob(A|info)$ and $Prob(B|info)$ 

As for the priors, let's assign a uniform distribtuion: $Prob(A) = Prob(B) = Prob(C) = 1/3$    

What is the likelihood, $Prob(info|A)$?  

What is the likelihood, $Prob(info|B)$? 

Now we need the denominator, $Prob(info)$. The easiest way to get this unconditional probability is to rearrange the equation for conditional probability:

$Prob(info) = Prob(info|A)\cdot Prob(A) + Prob(info|B)\cdot Prob(B) + Prob(info|C)\cdot Prob(C)$
(either A is true *or* B is true *or* C is true).

So what's the answer?

### Can we simulate this result to convince ourselves that switching is the right move? Here is an R function for doing this:

```{r}
##### Monty Hall simulation code (code by Corey Chivers 2012)
#####################################################
# Simulation of the Monty Hall Problem
# Demonstrates that switching is always better
# than staying with your initial guess
#
# Corey Chivers, 2012
#####################################################
 
monty<-function(strat='stay',N=1000,print_games=TRUE){
  doors<-1:3 #initialize the doors behind one of which is a good prize
  win<-0 #to keep track of number of wins
  
  for(i in 1:N){
    prize<-floor(runif(1,1,4)) #randomize which door has the good prize
    guess<-floor(runif(1,1,4)) #guess a door at random
    
    ## Reveal one of the doors you didn't pick which has a bum prize
    if(prize!=guess)
      reveal<-doors[-c(prize,guess)]
    else
      reveal<-sample(doors[-c(prize,guess)],1)
    
    ## Stay with your initial guess or switch
    if(strat=='switch')
      select<-doors[-c(reveal,guess)]
    if(strat=='stay')
      select<-guess
    if(strat=='random')
      select<-sample(doors[-reveal],1)
    
    ## Count up your wins
    if(select==prize){
      win<-win+1
      outcome<-'Winner!'
    }else
      outcome<-'Loser!'
    
    if(print_games)
      cat(paste('Guess: ',guess,
          '\nRevealed: ',reveal,
          '\nSelection: ',select,
          '\nPrize door: ',prize,
          '\n',outcome,'\n\n',sep=''))
  }
  cat(paste('Using the ',strat,' strategy, your win percentage was ',win/N*100,'%\n',sep='')) #Print the win percentage of your strategy
}

```


Now we can test out the different strategies.

```{r}
monty(strat="stay",print_games=FALSE)

```


What if we had more prior information – say, there was a strong smell of goat coming from door A?   
The priors would be different ( $Prob(A) > Prob(B)$ ). The likelihoods would remain exactly the same, but the posterior for A would be greater than 1/3. That’s the value of the Bayesian approach – it can integrate all the available information! Think about the XKCD comic above...


5. Features of probability distributions
Discrete vs. continuous
In discrete distributions, each outcome has a specific probability ( like the probability of
flipping a coin 10 times and getting 4 heads). In continuous distributions, the height of
the curve corresponds to probability density, f(x), not probability P(x). This is because
the probability of getting exactly one value in a continuous distribution is effectively
zero. This arises from the problem of precision. The sum of the probability distribution
must be 1 (there is only 100% of probability to go around). So the sum of all P(x) must
be 1. But in a continuous distribution, there are an infinite number of values of x (think
about it – between x = 2.01 and x = 2.02 are the numbers 2.001, 2.002, 2.003, ..., and
between those are 2.0001, 2.0002, 2.0003, ... The number line is infinitely divisible). So
any individual probability is always divided by infinity, which makes it zero. The long
and short of this is that we have to talk about probability density, unless we want to
specify a particular range of values – we can’t calculate P(x = 5), but we can calculate
P(4 < x < 6) or P(x > 5).
For this reason, when dealing with continuous distributions, the likelihood P(θ|H) will
have to be a probability density f(θ|H). So likelihoods are not always probabilities.
Some other distributional lingo:
Moments – descriptions of the shaped & central tendency of the distribution
Parameters – the values in the probability distribution function that define the shape of
the pdf. Parametric statistics require assuming certain things about distributions &
parameters, while nonparametric stats do not require these assumptions.
6. Some probability distributions
Most of the distributions we use were originally formulated in industrial applications and
then rejiggered for ecology. That’s why most of them deal with waiting times, failures,
etc. Bolker explains the main ones. Pay particular attention to the type of process
described by each distribution. The key to using these correctly is to figure out which
statistical process best matches the ecological process you’re studying, then use that
distribution. e.g., Am I observing independent, random events occurring in a fixed
window of time or space (like sampling barnacles in quadrats on an intertidal bench)?
Then the distribution of their occurrence probably follows a Poisson distribution.